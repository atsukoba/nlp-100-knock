{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# 言語処理100本ノック\n",
    "# 第6章: 英語テキストの処理\n",
    "\n",
    "---\n",
    "\n",
    "英語のテキスト（`nlp.txt`）に対して，以下の処理を実行せよ．\n",
    "\n",
    "- [Stanford CORE NLP](https://stanfordnlp.github.io/CoreNLP/)を用いる。  \n",
    "\n",
    "- [`nlp.txt`](http://www.cl.ecei.tohoku.ac.jp/nlp100/data/nlp.txt)\n",
    "\n",
    "> `nlp.txt`: 英語のWikipedia記事**\"Natural Language Processing\"**を１行１文形式にまとめたものです．このファイルはクリエイティブ・コモンズ 表示-継承 3.0 非移植のライセンスで配布されています．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(\"nlp.txt\"):\n",
    "    print(\"nlp.txt has already been exist!\")\n",
    "else:\n",
    "    os.system(\"wget -O nlp.txt http://www.cl.ecei.tohoku.ac.jp/nlp100/data/nlp.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural language processing\n",
      "From Wikipedia, the free encyclopedia\n",
      "\n",
      "Natural language processing (NLP) is a field of computer science, artificial intelligence, and linguistics concerned with the interactions between computers and human (natural) languages. As such, NLP is related to the area of humani-computer interaction. Many challenges in NLP involve natural language understanding, that is, enabling computers to derive meaning from human or natural language input, and others involve natural language generation.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "head -5 nlp.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 50. 文区切り\n",
    "\n",
    "---\n",
    "\n",
    "(`.` or `;` or `:` or `?` or `!`) → 空白文字 → 英大文字というパターンを文の区切りと見なし，入力された文書を1行1文の形式で出力せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 51. 単語の切り出し\n",
    "\n",
    "---\n",
    "\n",
    "空白を単語の区切りとみなし，50の出力を入力として受け取り，1行1単語の形式で出力せよ．ただし，文の終端では空行を出力せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 52. ステミング\n",
    "\n",
    "---\n",
    "\n",
    "51の出力を入力として受け取り，Porterのステミングアルゴリズムを適用し，単語と語幹をタブ区切り形式で出力せよ． Pythonでは，Porterのステミングアルゴリズムの実装としてstemmingモジュールを利用するとよい．\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 53. Tokenization\n",
    "\n",
    "---\n",
    "\n",
    "`Stanford Core NLP`を用い，入力テキストの解析結果をXML形式で得よ．また，このXMLファイルを読み込み，入力テキストを1行1単語の形式で出力せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 54. 品詞タグ付け\n",
    "\n",
    "---\n",
    "\n",
    "`Stanford Core NLP`の解析結果XMLを読み込み，単語，レンマ，品詞をタブ区切り形式で出力せよ．\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 55. 固有表現抽出\n",
    "\n",
    "---\n",
    "\n",
    "入力文中の人名をすべて抜き出せ．\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 56. 共参照解析\n",
    "\n",
    "---\n",
    "\n",
    "`Stanford Core NLP`の共参照解析の結果に基づき，文中の参照表現（`mention`）を代表参照表現（`representative mention`）に置換せよ．ただし，置換するときは，「代表参照表現（参照表現）」のように，元の参照表現が分かるように配慮せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 57. 係り受け解析\n",
    "\n",
    "---\n",
    "\n",
    "`Stanford Core NLP`の係り受け解析の結果（`collapsed-dependencies`）を有向グラフとして可視化せよ．可視化には，係り受け木をDOT言語に変換し，`Graphviz`を用いるとよい．また，Pythonから有向グラフを直接的に可視化するには，`pydot`を使うとよい．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 58. タプルの抽出\n",
    "\n",
    "---\n",
    "\n",
    "`Stanford Core NLP`の係り受け解析の結果（`collapsed-dependencies`）に基づき，「主語 述語 目的語」の組をタブ区切り形式で出力せよ．ただし，主語，述語，目的語の定義は以下を参考にせよ．\n",
    "\n",
    "述語: nsubj関係と`dobj`関係の子（dependant）を持つ単語\n",
    "主語: 述語から`nsubj`関係にある子（dependent）\n",
    "目的語: 述語から`dobj`関係にある子（dependent）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 59. S式の解析\n",
    "\n",
    "---\n",
    "\n",
    "`Stanford Core NLP`の句構造解析の結果（S式）を読み込み，文中のすべての名詞句（NP）を表示せよ．入れ子になっている名詞句もすべて表示すること．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
