{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 言語処理100本ノック\n",
    "# 第8章: 機械学習\n",
    "\n",
    "---\n",
    "\n",
    "本章では，Bo Pang氏とLillian Lee氏が公開している`Movie Review Dataのsentence polarity dataset v1.0`を用い，文を肯定的（ポジティブ）もしくは否定的（ネガティブ）に分類するタスク（極性分析）に取り組む．\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rt-polaritydata/ has already been exist!\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(\"rt-polaritydata/\"):\n",
    "    print(\"rt-polaritydata/ has already been exist!\")\n",
    "else:\n",
    "    os.system(\"wget -O rt-polaritydata.tar.gz http://www.cs.cornell.edu/people/pabo/movie-review-data/rt-polaritydata.tar.gz\")\n",
    "    os.system(\"tar -zxvf rt-polaritydata.tar.gz\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: -l: No such file or directory\n",
      "rt-polaritydata/:\n",
      "rt-polarity.neg  rt-polarity.pos\n"
     ]
    }
   ],
   "source": [
    "ls rt-polaritydata/ -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the rock is destined to be the 21st century's new \" conan \" and that he's going to make a splash even greater than arnold schwarzenegger , jean-claud van damme or steven segal . \n",
      "the gorgeously elaborate continuation of \" the lord of the rings \" trilogy is so huge that a column of words cannot adequately describe co-writer/director peter jackson's expanded vision of j . r . r . tolkien's middle-earth . \n",
      "effective but too-tepid biopic\n",
      "simplistic , silly and tedious . \n",
      "it's so laddish and juvenile , only teenage boys could possibly find it funny . \n",
      "exploitative and largely devoid of the depth or sophistication that would make watching such a graphic treatment of the crimes bearable . \n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "head -3 rt-polaritydata/rt-polarity.pos\n",
    "\n",
    "head -3 rt-polaritydata/rt-polarity.neg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "nkf -w --overwrite rt-polaritydata/*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check(l: list, head=5) -> None:\n",
    "    \"\"\"\n",
    "    Data Helper check()\n",
    "    \n",
    "    Params\n",
    "    ------\n",
    "    l: list\n",
    "        list that you want to check\n",
    "\n",
    "    head: int\n",
    "        size, length of sample log output\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    output sentence for checking list object\n",
    "    structure and size.\n",
    "    \"\"\"\n",
    "    output = \"\"\n",
    "    output += \"Length: {}\\n\".format(len(l))\n",
    "    output += \"First {} elements: {}\".format(head, l[:head])\n",
    "    print(output)\n",
    "    return\n",
    "\n",
    "def tokenize(sentence: str) -> list:\n",
    "    return sentence.split(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 70. データの入手・整形\n",
    "\n",
    "文に関する極性分析の正解データを用い，以下の要領で正解データ（sentiment.txt）を作成せよ．\n",
    "\n",
    "`rt-polarity.pos`の各行の先頭に**\"+1 \"**という文字列を追加する（極性ラベル\"+1\"とスペースに続けて肯定的な文の内容が続く）\n",
    "`rt-polarity.neg`の各行の先頭に**\"-1 \"**という文字列を追加する（極性ラベル\"-1\"とスペースに続けて否定的な文の内容が続く）\n",
    "上述1と2の内容を結合（concatenate）し，行をランダムに並び替える\n",
    "`sentiment.txt`を作成したら，正例（肯定的な文）の数と負例（否定的な文）の数を確認せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def random_concat(pos=\"./rt-polaritydata/rt-polarity.pos\",\n",
    "                  neg=\"./rt-polaritydata/rt-polarity.neg\",\n",
    "                  seed=1, output_file_name=\"sentiment.txt\") -> tuple:\n",
    "    \"\"\"\n",
    "    70.「rt-polarity.posの各行の先頭に\"+1 \"という文字列を追加する\n",
    "    （極性ラベル\"+1\"とスペースに続けて肯定的な文の内容が続く）\n",
    "    rt-polarity.negの各行の先頭に\"-1 \"という文字列を追加する\n",
    "    （極性ラベル\"-1\"とスペースに続けて否定的な文の内容が続く）\n",
    "    上述1と2の内容を結合（concatenate）し，行をランダムに並び替える\n",
    "    sentiment.txtを作成したら，正例（肯定的な文）の数と負例（否定的な文）の数を確認せよ．」\n",
    "\n",
    "    Params\n",
    "    ------\n",
    "    pos : str\n",
    "        file path to pos-data text file\n",
    "    neg : str\n",
    "        negative one\n",
    "    seed : int (default: 1)\n",
    "        seed value for random function\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    output : str\n",
    "        randomly concatenated text.\n",
    "    \"\"\"\n",
    "    \n",
    "    labels = list()\n",
    "\n",
    "    with open(pos, encoding=\"utf-8\") as p:\n",
    "        pos = [\"+1\" + \" \" + str(line.rstrip()) for line in p.readlines()]\n",
    "\n",
    "    with open(neg, encoding=\"utf-8\") as n:\n",
    "        neg = [\"-1\" + \" \" + str(line.rstrip()) for line in n.readlines()]\n",
    "\n",
    "    output = pos + neg\n",
    "    \n",
    "    random.seed(seed)\n",
    "    random.shuffle(output)\n",
    "\n",
    "    labels = [1] * len(pos) + [0] * len(neg)\n",
    "    random.seed(seed)\n",
    "    random.shuffle(labels)\n",
    "    \n",
    "    print(\"Randomized text list.\")\n",
    "    check(output, head=1)\n",
    "\n",
    "    with open(output_file_name, \"w\") as w:\n",
    "        w.writelines(output)\n",
    "\n",
    "    return \"\\n\".join(output), labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomized text list.\n",
      "Length: 10661\n",
      "First 1 elements: ['-1 a negligible british comedy .']\n",
      "positive file P=5330\n",
      "negative file N=5331\n"
     ]
    }
   ],
   "source": [
    "sentiment, labels = random_concat()\n",
    "\n",
    "# 正例（肯定的な文）の数と負例（否定的な文）の数を確認せよ．\n",
    "print(\"positive file P={}\".format(labels.count(1)))\n",
    "print(\"negative file N={}\".format(labels.count(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "# len(list(map(bool, labels)))\n",
    "# pd.Series(sentiment.split(\"\\n\"))[(list(map(bool, labels)))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## 71. ストップワード\n",
    "\n",
    "英語のストップワードのリスト（ストップリスト）を適当に作成せよ．さらに，引数に与えられた単語（文字列）がストップリストに含まれている場合は真，それ以外は偽を返す関数を実装せよ．さらに，その関数に対するテストを記述せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "stop_words = [\"at\", \"in\", \"on\", \"by\", \"with\", \"of\",\n",
    "              \"I\", \"you\", \"am\", \"are\", \"it\", \"is\",\n",
    "              \"this\", \"that\", \"these\", \"those\", \"the\"]\n",
    "\n",
    "\n",
    "def is_stop_word(word : str) -> bool:\n",
    "    \"\"\"\n",
    "    英語のストップワードのリスト（ストップリスト）を適当に作成せよ．\n",
    "    さらに，引数に与えられた単語（文字列）がストップリストに含まれている場合は真，\n",
    "    それ以外は偽を返す関数を実装せよ．さらに，その関数に対するテストを記述せよ．\n",
    "    \"\"\"\n",
    "    return word in stop_words\n",
    "\n",
    "\n",
    "def have_stop_word(word : list) -> bool:\n",
    "    \"\"\"\n",
    "    英語のストップワードのリスト（ストップリスト）を適当に作成せよ．\n",
    "    さらに，引数に与えられた単語（文字列）がストップリストに含まれている場合は真，\n",
    "    それ以外は偽を返す関数を実装せよ．さらに，その関数に対するテストを記述せよ．\n",
    "    \"\"\"\n",
    "    if type(word) == str:\n",
    "        word = tokenize(word)\n",
    "    \n",
    "    return (True in [stop_word in word for stop_word in stop_words])\n",
    "\n",
    "\n",
    "def remove_stop_word(words : list) -> list:\n",
    "    \n",
    "    if type(words) == str:\n",
    "        words = tokenize(words)\n",
    "    \n",
    "    for sw in stop_words:\n",
    "        if sw in words:\n",
    "            words.remove(sw)\n",
    "\n",
    "    return words\n",
    "\n",
    "\n",
    "# check it\n",
    "print(is_stop_word(\"this\"))\n",
    "print(have_stop_word(\"the gorgeously elaborate continuation of\"))\n",
    "print(have_stop_word(\"gorgeously elaborate continuation\"))\n",
    "print(have_stop_word(remove_stop_word(\"the gorgeously elaborate continuation of\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 72. 素性抽出\n",
    "\n",
    "極性分析に有用そうな素性を各自で設計し，学習データから素性を抽出せよ．素性としては，レビューからストップワードを除去し，各単語をステミング処理したものが最低限のベースラインとなるであろう．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 73. 学習\n",
    "\n",
    "72で抽出した素性を用いて，ロジスティック回帰モデルを学習せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 74. 予測\n",
    "73で学習したロジスティック回帰モデルを用い，与えられた文の極性ラベル（正例なら\"+1\"，負例なら\"-1\"）と，その予測確率を計算するプログラムを実装せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 75. 素性の重み\n",
    "73で学習したロジスティック回帰モデルの中で，重みの高い素性トップ10と，重みの低い素性トップ10を確認せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 76. ラベル付け\n",
    "学習データに対してロジスティック回帰モデルを適用し，正解のラベル，予測されたラベル，予測確率をタブ区切り形式で出力せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 77. 正解率の計測\n",
    "76の出力を受け取り，予測の正解率，正例に関する適合率，再現率，F1スコアを求めるプログラムを作成せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 78. 5分割交差検定\n",
    "76-77の実験では，学習に用いた事例を評価にも用いたため，正当な評価とは言えない．すなわち，分類器が訓練事例を丸暗記する際の性能を評価しており，モデルの汎化性能を測定していない．そこで，5分割交差検定により，極性分類の正解率，適合率，再現率，F1スコアを求めよ．\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 79. 適合率-再現率グラフの描画\n",
    "\n",
    "ロジスティック回帰モデルの分類の閾値を変化させることで，適合率-再現率グラフを描画せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
